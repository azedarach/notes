---
title: "Differential Expression Analysis"
format:
  html:
    toc: true
bibliography: differential_expression.bib
---


```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(
  echo = TRUE,
  include = TRUE
  )
```

# Context

# Methods

## Linear Models

Approach underlying, e.g., limma [@Ritchie2015]. Formulated
initially in the context of analysis of microarray data,
e.g. [@Smyth2004]. For the $g^{\text{th}}$ gene, let
$y_{g1}, \dots, y_{gn}$ be the measured response values. For
microarray data, for example, $y_{gi}$ is usually either
the log-ratio $\log_2 R_{gi} - \log_2 G_{gi}$ (for two-colour
arrays) or log-intensity (for one colour arrays) measured
for gene $g$ in array $i$.

After normalising to remove unwanted technical variation, the
response is assumed to be described by the linear model
\begin{equation}
\mathrm{E}[\mathbf{y}_g] = X \mathbf{\alpha}_g ,
\end{equation}
where $\mathbf{y}_g^\prime = (y_{g1},\dots,y_{gn})$, $X$ is 
a suitable design matrix, and $\mathbf{\alpha}_g$ is the
coefficient vector. The variance is allowed to vary across
genes, such that
\begin{equation}
\mathrm{Var}[\mathbf{y}_g] = W_g \sigma_g^2 ,
\end{equation}
where $W_g$ is a (known) non-negative matrix of weights.

Biological contrasts of interest are encoded as
\begin{equation}
\mathbf{\beta}_g = C^\prime \mathbf{\alpha}_g ,
\end{equation}
for suitable $C$. The general problem in a differential
expression analysis is to assess whether particular contrasts
within this set are zero (i.e. not differentially expressed).

Estimates $\hat{\mathbf{\alpha}}_g$ and $s_g^2$ of the unknown parameters
$\mathbf{\alpha}_g$ and $\sigma_g^2$ are assumed to be available,
with estimated covariance matrices
\begin{equation}
\mathrm{Var}[\hat{\mathbf{\alpha}}_g] = V_g s_g^2 .
\end{equation}
In the case that $V_g$ depends on $\mathbf{\alpha}_g$, then it is
assumed that $V_g$ is evaluated at the estimate $\hat{\mathbf{\alpha}}_g$,
with this dependence ignorable to first-order. Estimators for the
contrasts of interest are
\begin{equation}
\hat{\mathbf{\beta}}_g = C^\prime \hat{\mathbf{\alpha}}_g ,
\end{equation}
with
\begin{equation}
\mathrm{Var}[\hat{\mathbf{\beta}}_g] = C^\prime V_g C s_g^2 .
\end{equation}
To develop the hierarchical model proposed in [@Smyth2004], it
is assumed that the contrasts $\hat{\mathbf{\beta}}_g$ are
normally distributed with mean $\mathbf{\beta}_g$ and
covariance matrix $C^\prime V_g C \sigma_g^2$, and $s_g^2$
is approximately distributed according to a scaled
$\chi^2$ distribution,
\begin{equation}
\begin{aligned}
s_g^2 | \sigma_g^2 &\sim \frac{\sigma_g^2}{d_g} \chi_{d_g}^2 , \\
\hat{\beta}_{gj} | \beta_{gj}, \sigma_g^2 &\sim
N(\beta_{gj}, v_{gj} \sigma_g^2) ,
\end{aligned}
\end{equation}
where $v_{gj}$ is the $j^{\text{th}}$ diagonal element of
$C^\prime V_g C$ and $d_g$ is the residual d.f. for the linear
model for gene $g$. This implies that 
$\hat{\beta}_{gj} / \sigma_{g} \sqrt{v_{gj}} |
\beta_{gj},\sigma_g^2 \sim N(\beta_{gj}, 1)$,
$s_g^2 d_g / \sigma_g^2 | \sigma_g^2 \sim \chi_{d_g}^2$,
and the test statistic
\begin{equation}
t_{gj} = \frac{\hat{\beta}_{gj}}{s_g \sqrt{v_{gj}}} =
\frac{\frac{\hat{\beta}_{gj}}{\sigma_g \sqrt{v_{gj}}}}
{\sqrt{\frac{s_g^2 d_g}{d_g \sigma_g^2}}}
\end{equation}
is approximately $t_{d_g}$-distributed under the null
$\beta_{gj} = 0$. Estimators for distinct genes $g_1$ and $g_2$
are assumed independent. For $\sigma_g^2$, a prior of the form
\begin{equation}
\frac{1}{\sigma_g^2} \sim \frac{1}{d_0 s_0^2} \chi_{d_0}^2
\end{equation}
is assumed. For $\beta_{gj}$, the prior is taken to be a mixture
of a point mass at zero, with mixing probability
$1 - \mathrm{Pr}(\beta_{gj} \neq 0) \equiv 1 - p_j$, and
the conjugate normal prior
\begin{equation}
\beta_{gj} | \sigma_g^2, \beta_{gj} \neq 0 \sim
N(0, v_{0j} \sigma_g^2) .
\end{equation}
The likelihood, conditional on $\mathbf{\beta}_g$ and
$\sigma_g^2$, for a given $\beta_{gj}$ and $s_g^2$ is
\begin{equation}
p(\hat{\beta}_{gj}, s_g^2 | \mathbf{\beta}, \sigma_g^2) =
p(\hat{\beta}_{gj} | \beta_{gj} \sigma_g^2)
p(s_g^2 | \sigma_g^2) ,
\end{equation}
where the relevant densities are
\begin{equation}
\begin{aligned}
p(s_g^2 | \sigma_g^2) &=
\frac{d_g \sigma_g^{-2}}{2^{\frac{d_g}{2}} \Gamma(d_g/2)}
(s_g^2 d_g \sigma_g^{-2})^{\frac{d_g}{2}-1} \exp \left [
  -\frac{s_g^2 d_g \sigma_g^{-2}}{2} \right ] , \\
  p(\hat{\beta}_{gj} | \beta_{gj}, \sigma_g^2) &=
  \frac{1}{\sqrt{2 \pi v_{gj} \sigma_g^2}} \exp \left [
   -\frac{(\hat{\beta}_{gj} - \beta_{gj})^2}{2 v_{gj} \sigma_g^2}
    \right ] .
\end{aligned}
\end{equation}
The joint distribution for $\hat{\beta}_{gj}$ and $s_g^2$
conditional on $\beta_{gj}$ can then be calculated,
\begin{align*}
p(\hat{\beta}_{gj}, s_g^2 | \beta_{gj}) &=
\int p(\hat{\beta}_{gj}, s_g^2, 
\sigma_g^{-2} | \beta_{gj}) d\sigma_g^{-2} \\
&= \int p(\hat{\beta}_{gj}, s_g^2 | \beta_{gj}, \sigma_g^{-2})
p(\sigma_g^{-2}) d\sigma_g^{-2} \\
&= \int p(\hat{\beta}_{gj} | \beta_{gj} \sigma_g^2)
p(s_g^2 | \sigma_g^2)
p(\sigma_g^{-2}) d\sigma_g^{-2} .
\end{align*}
Plugging in the above densities, along with the prior
\begin{equation}
p(\sigma_g^{-2}) = \frac{d_0 s_0^2}{2^{d_0/2} \Gamma(d_0/2)}
(d_0 s_0^2 \sigma_g^{-2})^{\frac{d_0}{2}-1}
\exp \left [ -\frac{d_0 s_0^2 \sigma_g^{-2}}{2} \right ] ,
\end{equation}
gives under the null $\beta_{gj} = 0$,
\begin{align}
p(\hat{\beta}_{gj}, s_g^2 | \beta_{gj} = 0) &=
\frac{1}{\sqrt{2 v_{gj}}} \left ( \frac{d_0 s_0^2}{2} \right )^{d_0/2}
\left ( \frac{d_g}{2} \right )^{d_g/2}
\frac{s_g^{2 ( d_g/2-1)}}{B(1/2, d_0/2, d_g/2)} \nonumber \\
& \quad {} \times \left ( \frac{\hat{\beta}_{gj}^2 / v_{gj} +
d_0 s_0^2 + d_g s_g^2}{2} \right )^{-(d_g + d_0 + 1)/2} ,
\end{align}
with
\begin{equation}
B(x_1, x_2, x_3) \equiv \frac{\Gamma(x_1) \Gamma(x_2) \Gamma(x_3)}
{\Gamma(x_1 + x_2 + x_3)} .
\end{equation}
Similarly, for $\beta_{gj} \neq 0$, after additionally marginalising
over the prior for $\beta_{gj}$,
\begin{align}
p(\hat{\beta}_{gj}, s_g^2 | \beta_{gj} \neq 0) &=
\frac{1}{\sqrt{2 (v_{0j} + v_{gj})}} \left (
  \frac{d_0 s_0^2}{2} \right )^{d_0/2}
\left ( \frac{d_g}{2} \right )^{d_g/2}
\frac{s_g^{2 ( d_g/2-1)}}{B(1/2, d_0/2, d_g/2)} \nonumber \\
& \quad {} \times \left ( \frac{\hat{\beta}_{gj}^2 / (v_{0j}+v_{gj}) +
d_0 s_0^2 + d_g s_g^2}{2} \right )^{-(d_g + d_0 + 1)/2} .
\end{align}

The above choice of priors implies that, conditional on
$s_g^2$,
\begin{equation}
p(\sigma_g^{-2}|s_g^2) \propto
(\sigma_g^{-2})^{\frac{d_g + d_0}{2} - 1}
\exp \left [ -\frac{\sigma_g^{-2}}{2} (s_g^2 d_g + s_0^2 d_0)
\right ] ,
\end{equation}
and hence
\begin{equation}
\tilde{s}_g^{-2} \equiv E[\sigma_g^{-2} | s_g^2] =
\frac{d_0 + d_g}{d_0 s_0^2 + d_g s_g^2} .
\end{equation}
Define the moderated $t$-statistic by
\begin{equation}
\tilde{t}_{gj} = \frac{\hat{\beta}_{gj}}
{\tilde{s}_g \sqrt{v_{gj}}}.
\end{equation}
Then since, under the change of variables $\hat{\beta}_{gj} \to
\tilde{t}_{gj}$,
\begin{equation}
p(\tilde{t}_{gj}, s_g^2 | \beta_{gj}) = \tilde{s} \sqrt{v_{gj}}
p(\hat{\beta}_{gj}, s_g^2 | \beta_{gj}),
\end{equation}
it follows that
\begin{align}
p(\tilde{t}_{gj}, s_g^2 | \beta_{gj} = 0) &=
\frac{(d_0 s_0^2)^{d_0/2} d_g^{d_g/2} s_g^{2(d_g/2-1)}}
{B(d_0/2, d_g/2) (d_0 s_0^2 + d_g s_g^2)^{\frac{d_0+d_g}{2}}} \nonumber \\
& \quad {} \times \frac{(d_0 + d_g)^{-1/2}}{B(1/2, d_0/2+d_g/2)}
\left ( 1 + \frac{\tilde{t}_{gj}^2}{d_0 + d_g}
 \right )^{-\frac{1}{2} (d_0 + d_g + 1)} ,
\end{align}
and
\begin{align}
p(\tilde{t}_{gj}, s_g^2 | \beta_{gj} \neq 0) &=
\frac{(d_0 s_0^2)^{d_0/2} d_g^{d_g/2} s_g^{2(d_g/2-1)}}
{B(d_0/2, d_g/2) (d_0 s_0^2 + d_g s_g^2)^{\frac{d_0+d_g}{2}}} \nonumber \\
& \quad {} \times \frac{1}{\left ( 1 + \frac{v_{0j}}{v_{gj}}
\right )^{1/2}}
\frac{(d_0 + d_g)^{-1/2}}{B(1/2, d_0/2+d_g/2)}
\left ( 1 + \frac{1}{d_0 + d_g} \left [ \frac{\tilde{t}_{gj}}{\left (
  1 + \frac{v_{0j}}{v_{gj}} \right)^{1/2}}\right]^2
 \right )^{-\frac{1}{2} (d_0 + d_g + 1)} .
\end{align}
Hence, $\tilde{t}_{gj}$ and $s_g^2$ are independent with
$s_g^2 \sim s_0^2 F_{d_g,d_0}$ while
\begin{equation}
\begin{aligned}
\tilde{t}_{gj} | \beta_{gj} = 0 &\sim t_{d_0 + d_g} , \\
\tilde{t}_{gj} | \beta_{gj} \neq 0 &\sim \left ( 1 + \frac{v_{0j}}{v_{gj}}
\right )^{1/2} t_{d_0 + d_g} ,
\end{aligned}
\end{equation}
i.e., $\tilde{t}_{gj}$ is a mix of a scaled $t$-distribution and
ordinary $t$-distribution, with mixing proportions $p_j$ and $1 - p_j$.

The above expressions for the posterior distributions allow the
posterior odds $O_{gj}$ that the gene $g$ is differentially expressed 
in the $j^{\text{th}}$ contrast (i.e., the posterior odds that
$\beta_{gj} \neq 0$) to be computed. Since
\begin{equation}
O_{gj} = \frac{p(\beta_{gj} \neq 0 | \tilde{t}_{gj}, s_g^2)}
{p(\beta_{gj} = 0 | \tilde{t}_{gj}, s_g^2)} =
\frac{p(\tilde{t}_{gj}, s_g^2 | \beta_{gj} \neq 0) p(\beta_{gj} \neq 0)}
{p(\tilde{t}_{gj}, s_g^2 | \beta_{gj} = 0) p(\beta_{gj} = 0)} =
\frac{p(\tilde{t}_{gj}| \beta_{gj} \neq 0) p_j}
{p(\tilde{t}_{gj}| \beta_{gj} = 0) (1 - p_j)} ,
\end{equation}
substituting the above expressions for the posterior distribution of
$\tilde{t}_{gj}$ gives
\begin{equation}
O_{gj} = \frac{p_j}{1-p_j} \left ( \frac{v_{gj}}{v_{gj} + v_{0j}}
\right )^{1/2} \left ( \frac{\tilde{t}_{gj}^2 + d_0 + d_g}
{\tilde{t}_{gj}^2 \frac{v_{gj}}{v_{gj} + v_{0j}} + d_0 + d_g}
  \right )^{(d_0 + d_g + 1)/2} .
\end{equation}

The linear modelling approach employed by limma
estimates the hyperparameters using an empirical Bayes
approach. Since each $s_g^2$ is distributed according to
a scaled $F$-distribution,
\begin{equation}
z_g = \ln s_g^2
\end{equation}
is distributed as a constant plus Fisher's $z$-distribution.
Moreover,
\begin{equation}
\begin{aligned}
E[z_g] &= \ln s_0^2 + \psi(d_g / 2) - \psi(d_0 / 2) +
\ln \frac{d_0}{d_g} , \\
\mathrm{Var}[z_g] &= \psi^\prime(d_g/2) + \psi^\prime(d_0/2) ,
\end{aligned}
\end{equation}
where $\psi(x)$ and $\psi^\prime(x)$ are the digamma and
trigamma functions. Let
\begin{equation}
e_g = z_g - \psi(d_g/2) + \ln(d_g/2)
\end{equation}
and
\begin{equation}
\bar{e} = \frac{1}{G} \sum_{g=1}^G e_g ,
\end{equation}
where $G$ is the number of genes. Then
\begin{equation}
E\left [ \frac{(e_g - \bar{e})^2 G}{G - 1} -
\psi^\prime(d_g/2)\right ]\approx \psi^\prime(d_0/2) .
\end{equation}
An estimate for $d_0$ is thus found by solving
\begin{equation}
\psi^\prime(d_0/2) = \frac{1}{G} \sum_{g=1}^G \left \{ 
 \frac{(e_g - \bar{e})^2 G}{G - 1} -
\psi^\prime(d_g/2) \right \} .
\end{equation}
The solution for $d_0$ can then be used to estimate
\begin{equation}
s_0^2 = \exp \left [ \bar{e} + \psi(d_0/2) - \ln(d_0/2)
 \right ] .
\end{equation}
When a solution for $d_0$ does not exist, i.e., when the
relevant sample mean is non-positive, there is no evidence
that the $\sigma_g^2$ vary between genes. In this case,
we set $d_0 \to \infty$ and $s_0^2 = \exp(\bar{e})$.

Estimation of $v_{0j}$ proceeds from the cumulative distribution
function for $\tilde{t}_{gj}$,
\begin{equation}
F(\tilde{t}_{gj}; v_{gj}, d_0 + d_g) = p_j F \left (
 \tilde{t}_{gj} \left [ \frac{v_{gj}}{v_{gj}+v_{0j}}
 \right ]^{1/2}; d_0 + d_g \right) +
 (1 - p_j) F(\tilde{t}_{gj}; d_0 + d_g) .
\end{equation}
Here $F(t; k)$ is the $t$-distribution CDF on $k$ degrees of
freedom. Let $r$ be the rank of gene $g$ when $|\tilde{t}_{gj}|$
are sorted in descending order. To estimate $v_{0j}$, the
computed $p$-value for each $|\tilde{t}_{gj}|$ is matched
to its nominal value based on its rank, by solving
\begin{equation}
2 F(-|\tilde{t}_{gj}|; v_{gj} , v_{0j}, d_0 + d_g) =
\frac{r - 0.5}{G} .
\end{equation}
The solution is
\begin{equation}
v_{0j} = v_{gj} \left (
  \frac{\tilde{t}_{gj}^2}{q_{\textrm{target}}^2} - 1\right )
\end{equation}
where
\begin{equation}
q_{\textrm{target}} = F^{-1}(p_{\textrm{target}}; d_0 + d_g)
\end{equation}
and
\begin{equation}
p_{\textrm{target}} = \frac{1}{p_j} \left [
 \frac{r - 0.5}{2G} - (1 - p_j) F(-|\tilde{t}_{gj}|;
 d_0 + d_g ) \right ] ,
\end{equation}
provided that $p_{\textrm{target}} \in (0, 1)$ and
$q_{\textrm{target}} \leq |\tilde{t}_{gj}|$. When
$|tilde{t}_{gj}|$ lies above the line of equality on a
$t$-distribution probability plot, then $p_{\textrm{target}} > 0$
and $v_{0j} > 0$. Additionally, $p_{\textrm{target}} < 1$ for
those genes for which $(r - 0.5) / (2G) < p_j$. When
$|\tilde{t}_{gj}|$ lies below the line of equality, the
best estimate for $v_{0j} = 0$. Hence, to estimate $v_{0j}$,
for each of the genes with rank $r = 1, \dots, G p_j/2$,
the individual estimate for $v_{0j}$ is calculated and the
estimate for $v_{0j}$ is set to the mean of these estimates.
If all such $|\tilde{t}_{gj}|$ lie below the line of equality,
then $v_{0j}$ is estimated as zero.

```{r}
#| label: session-info
sessionInfo()
```
